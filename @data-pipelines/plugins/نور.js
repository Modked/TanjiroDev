/*
 â€¢ Ø§ØªØ¹Ù…Ù„Øª Ø¨Ø¥ÙŠØ¯ Eslam âœŒï¸
 â€¢ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªØ®Ù„ØµØ© Ù…Ù† Shannz 
 â€¢ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ Ø§ØµØ¯Ø§Ø± llama-3.3-70b Ù…ØªÙÙˆÙ‚ Ø¹Ù„ÙŠ Meta Ai ğŸ˜
 â€¢ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ - Venice (ÙŠÙ‚Ø¯Ø± ÙŠØ¹Ù…Ù„ ØµÙˆØ± ğŸ’¥)
 â€¢ Ù…ØªØ´Ù„Ø´ Ø­Ù‚ÙˆÙ‚ Ø§Ù„ÙƒÙˆØ¯ Ø¹Ø´Ø§Ù† Ù…Ø§ ÙŠØ¨Ù‚Ø§Ø´ ÙÙŠÙ‡ Ù…Ø´Ø§ÙƒÙ„ âœ‹
 â€¢ https://whatsapp.com/channel/0029VasoQ3rEFeXn7Ij6oG37 */

import axios from "axios";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Ø¯Ø§Ù„Ø© ØªØ±Ø¬Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø© Google Translate Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©
const translateText = async (text, targetLang = "en") => {
  try {
    const response = await axios.get("https://translate.googleapis.com/translate_a/single", {
      params: {
        client: "gtx",
        sl: "auto", // Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ØµØ¯Ø± ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§
        tl: targetLang, // Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
        dt: "t",
        q: text, // Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ±Ø¬Ù…ØªÙ‡
      },
    });

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ±Ø¬Ù…
    return response.data[0][0][0];
  } catch (error) {
    console.error("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©:", error.message);
    throw new Error("âŒ Ù…Ø§Ø¹Ø±ÙØªØ´ Ø£ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ!");
  }
};

const handler = async (m, { text, command, args }) => {
  const venice = {
    chatbot: async (question, model = "llama-3.3-70b") => {
      const data = JSON.stringify({
        requestId: "scrape-for-all",
        modelId: model,
        prompt: [
          {
            content: question,
            role: "user",
          },
        ],
        systemPrompt: "",
        conversationType: "text",
        temperature: 0.8,
        webEnabled: true,
        topP: 0.9,
        isCharacter: false,
        clientProcessingTime: 2834,
      });

      const config = {
        method: "POST",
        url: "https://venice.ai/api/inference/chat",
        headers: {
          "User-Agent":
            "Mozilla/5.0 (Android 10; Mobile; rv:131.0) Gecko/131.0 Firefox/131.0",
          "Content-Type": "application/json",
          "accept-language": "id-ID",
          referer: "https://venice.ai/chat",
          "x-venice-version": "20241221.032412",
          origin: "https://venice.ai",
          "sec-fetch-dest": "empty",
          "sec-fetch-mode": "cors",
          "sec-fetch-site": "same-origin",
          priority: "u=4",
          te: "trailers",
        },
        data: data,
      };

      const res = await axios.request(config);
      const chunks = res.data
        .split("\n")
        .filter((chunk) => chunk)
        .map((chunk) => JSON.parse(chunk));
      const answer = chunks.map((chunk) => chunk.content).join("");
      return answer;
    },

    txt2img: async (prompt) => {
      // Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‡Ù†ØªØ±Ø¬Ù… Ø§Ù„Ø£ÙˆÙ„ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø© Google Translate Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©
      if (/[\u0600-\u06FF]/.test(prompt)) {
        prompt = await translateText(prompt, "en");
      }

      const data = JSON.stringify({
        modelId: "fluently-xl-final-akash",
        requestId: "INlNFRX",
        prompt: prompt,
        seed: 15391382,
        negativePrompt: "",
        cfgScale: 5,
        aspectRatio: "1:1",
        width: 1024,
        height: 1024,
        customSeed: "",
        steps: 30,
        isCustomSeed: false,
        isHighRes: false,
        safeVenice: true,
        stylePreset: "",
        hideWatermark: false,
        favoriteImageStyles: [],
        stylesTab: 0,
        loraStrength: 75,
        imageToImageStrength: 50,
        clientProcessingTime: 3808,
      });

      const config = {
        method: "POST",
        url: "https://venice.ai/api/inference/image",
        headers: {
          "User-Agent":
            "Mozilla/5.0 (Android 10; Mobile; rv:131.0) Gecko/131.0 Firefox/131.0",
          "Content-Type": "application/json",
          "accept-language": "id-ID",
          referer: "https://venice.ai/chat",
          "x-venice-version": "20241221.032412",
          origin: "https://venice.ai",
          "sec-fetch-dest": "empty",
          "sec-fetch-mode": "cors",
          "sec-fetch-site": "same-origin",
          priority: "u=4",
          te: "trailers",
        },
        responseType: "arraybuffer",
        data: data,
      };
      const res = await axios.request(config);
      const filePath = path.join(__dirname, "image.png");
      fs.writeFileSync(filePath, res.data);
      return filePath;
    },
  };

  if (command === "Ù†ÙˆØ±") {
    if (!args[0]) return m.reply("ğŸ§ Ø§ÙƒØªØ¨Ù„ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ø´Ø§Ù† Ø£Ø¬Ø§ÙˆØ¨Ùƒ ÙŠØ§ Ù…Ø¹Ù„Ù…!");
    const response = await venice.chatbot(args.join(" "));
    m.reply(`ğŸ¤– Ø§Ù„Ø±Ø¯ Ø¨ØªØ§Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ: ${response}`);
  }

  if (command === "ØªØµÙ…ÙŠÙ…") {
    if (!args[0])
      return m.reply("âŒ Ø§ÙƒØªØ¨ ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù„ÙŠ Ø¹Ø§ÙŠØ²Ù‡Ø§ ÙŠØ§ ÙÙ†Ø§Ù†!");
    const filePath = await venice.txt2img(args.join(" "));
    await conn.sendMessage(m.chat, {
      image: { url: filePath },
      caption: "ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§ØªØ¹Ù…Ù„Øª Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰",
    });
  }
};

handler.command = ["Ù†ÙˆØ±", "ØªØµÙ…ÙŠÙ…"];
handler.tags = ["ai"];
handler.help = [
  "Ù†ÙˆØ± + Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨ØªØ§Ø¹Ùƒ",
  "ØªØµÙ…ÙŠÙ… + Ø§Ù„ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø©",
];
export default handler;